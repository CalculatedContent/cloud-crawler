= Installing Cloud Crawler on Amazon AWS

== OVERVIEW

The Distributed Architecture requires a minimum of 3 servers:

* The <b>Chef Server</b>: used to configure Worker instances at creation
* The <b>Master Server</b>: hosts the global job Queue and the master Redis database
* A *Worker* instance: fetches jobs from the Queue on the Master and executes them

Note that both the Chef Server and the Master Server need to run on a Small instance minimum (m1.small).
However the workers are designed to run on the cheaper lightweight Mico instances (t1.micro)

You need at least one Worker instance to perform jobs, but you can spawn as many Workers as you want.

Currently, the Master instance must be started before any Worker.

== DEPENDENCIES

* Ruby 1.9.3
* knife ec2 gem (`gem install knife-ec2 --no-rdoc --no-ri`)
* Amazon AWS
* Amazon S3 for long term storage (optional)

== INSTALLATION

=== Chef Server

1. Clone the git repo for Chef:

 $ git clone https://github.com/CalculatedContent/chef-repo.git

2. Create a Key Pair from the AWS Management Console

Name it 'ec2-cc-chef' for example.
Save ec2-cc-chef.pem in ~/.ssh/ with the correct permissions (chmod 400).

3. Create a Security Groups 'chefami'

Open these ports:
* 22 (SSH)
* 80 (HTTP) - Used to access the Queue monitor on the Master Server
* 443 (HTTPS)
* 6379 (Redis)

4. Set the environment variables. In your ~/.bashrc it looks like this:

 export CHEF_AMI_ID='ami-d70c2892'
 export CHEF_USER='ubuntu'
 export CHEF_KEY='ec2-cc-chef'
 export CHEF_PEM='/home/ubuntu/.ssh/ec2-cc-chef.pem'
 
 export EC2_AVAILABILITY_ZONE='us-west-1c'
 export EC2_REGION='us-west-1'
 export AWS_ACCESS_KEY_ID='AKIAIVVVWWW'
 export AWS_SECRET_ACCESS_KEY='EHHD+qmnOj90923JN9NMFWOh/FAQuiq'

AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are your master credentials for your AWS account (found in Security Credentials).

IAM users will not work, even with Administrator Access.

5. Set up the default knife configuration

 $ cat ~/.chef/knife.rb
 knife[:identity_file]="#{ENV['CHEF_PEM']}"
 knife[:availability_zone]="#{ENV['EC2_AVAILABILITY_ZONE']}"
 knife[:aws_access_key_id]="#{ENV['AWS_ACCESS_KEY_ID']}"
 knife[:aws_secret_access_key]="#{ENV['AWS_SECRET_ACCESS_KEY']}"
 knife[:region]="#{ENV['EC2_REGION']}"

6. Run the Chef Server deployer:

 $ cd chef-repo/
 $ ./deploy_chef_server.sh

Follow the instructions in case of failure.
You will be asked to enter a password at some point.

=== Master Server

 $ deploy_cloud_master.sh

=== Worker instance

 $ deploy_cloud_worker.sh

Repeat as many times as you want to spawn new workers instances.
Note that by default Amazon EC2 accounts are limited to 20 instances.

Each worker instance, upon creation and configuration, will ask the Master instance if any jobs are in the job Queue.

== RUNNING JOBS

1. Pre-requsite

Make sure you have created the Chef Server, the Master Server and at least one Worker (see INSTALLATION above)

2. Log on the Master Server

 $ ssh -i $CHEF_PEM ubuntu@MasterServer

3. On the Master Server, populate the Job Queue

 $ cd ~/cc/cloud-crawler/
 $ sudo bundle exec examples/find_404s.rb -u http://calculatedcontent.com

The running Worker(s) will automatically pick up jobs from the Queue.

Spawn as many Workers as you need to execute the jobs faster.

4. Monitor the Job Queue by pointing your browser to the Master

 $ lynx http://Master_IP_Address
